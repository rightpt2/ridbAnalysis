{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "sns.set()\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are we doing here\n",
    "\n",
    "### Things to do\n",
    "<ol>\n",
    "    <li>Read differnet info from CSVs</li>\n",
    "    <li>Create quick data dictionary</li>\n",
    "    <li>Clean the data</li>\n",
    "    <li>Decide what we import to the DB</li>\n",
    "    <li>Load data into amazon postgres database</li>\n",
    "    <ol style=\"list-style-type: lower-alpha; padding-bottom: 0;\">\n",
    "      <li style=\"margin-left:1em\">How to connect / start a session</li>\n",
    "      <li style=\"margin-left:1em\">How to define schema</li>\n",
    "      <li style=\"margin-left:1em\">How to create a table</li>\n",
    "      <li style=\"margin-left:1em; padding-bottom: 0;\">How to load data</li>\n",
    "     </ol>\n",
    "    <li>Write some good queries</li>\n",
    "    <li>Create an ETL of Occupancy using jupyter</li> \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Data/Reservations/2008.csv',\n",
       " '../Data/Reservations/2009.csv',\n",
       " '../Data/Reservations/2018.csv',\n",
       " '../Data/Reservations/2015.csv',\n",
       " '../Data/Reservations/2014.csv',\n",
       " '../Data/Reservations/2016.csv',\n",
       " '../Data/Reservations/2017.csv',\n",
       " '../Data/Reservations/2013.csv',\n",
       " '../Data/Reservations/2007.csv',\n",
       " '../Data/Reservations/2006.csv',\n",
       " '../Data/Reservations/2012.csv',\n",
       " '../Data/Reservations/2010.csv',\n",
       " '../Data/Reservations/2011.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob(\"../Data/Reservations/*.csv\")\n",
    "files = files\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['HistoricalReservationID', 'OrderNumber', 'Agency', 'OrgID',\n",
       "       'CodeHierarchy', 'RegionCode', 'RegionDescription',\n",
       "       'ParentLocationID', 'ParentLocation', 'LegacyFacilityID', 'Park',\n",
       "       'SiteType', 'UseType', 'ProductID', 'EntityType', 'EntityID',\n",
       "       'FacilityID', 'FacilityZIP', 'FacilityState', 'FacilityLongitude',\n",
       "       'FacilityLatitude', 'CustomerZIP', 'CustomerState',\n",
       "       'CustomerCountry', 'Tax', 'UseFee', 'TranFee', 'AttrFee',\n",
       "       'TotalBeforeTax', 'TotalPaid', 'StartDate', 'EndDate', 'OrderDate',\n",
       "       'NumberOfPeople', 'Tent', 'Popup', 'Trailer', 'RVMotorhome',\n",
       "       'Boat', 'HorseTrailer', 'Car', 'FifthWheel', 'Van', 'CanoeKayak',\n",
       "       'BoatTrailer', 'Motorcycle', 'Truck', 'Bus', 'Bicycle',\n",
       "       'Snowmobile', 'OffRoadlAllTerrainVehicle', 'PowerBoat',\n",
       "       'PickupCamper', 'LargeTentOver9x12', 'SmallTent', 'Marinaboat',\n",
       "       'LatLongPoint'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The RIDB segments the sales data by year, lets check to make sure it has the same info in each file\n",
    "columns_data = {}\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(file, nrows=10)\n",
    "    columns_data[file] = df.columns.values\n",
    "\n",
    "# after printing the columns_data we see that it has the same columns in each sales file\n",
    "columns_data['../Data/Reservations/2018.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets write some quick functions to process our data\n",
    "\n",
    "def read_data(file):\n",
    "    print(file)\n",
    "    return pd.read_csv(file, low_memory=False)\n",
    "\n",
    "def trim_select_data(df):\n",
    "    \"\"\"quick funciton to clean up our data\"\"\"\n",
    "    \n",
    "    #first trim to only cols we care about\n",
    "    tgt_cols = ['HistoricalReservationID', 'OrderNumber', 'Agency', 'OrgID',\n",
    "       'CodeHierarchy', 'RegionCode', 'RegionDescription',\n",
    "       'ParentLocationID', 'ParentLocation', 'LegacyFacilityID', 'Park',\n",
    "       'SiteType', 'UseType', 'ProductID', 'EntityType', 'EntityID',\n",
    "       'FacilityID', 'FacilityZIP', 'FacilityState', 'FacilityLongitude',\n",
    "       'FacilityLatitude', 'CustomerZIP', 'CustomerState',\n",
    "       'CustomerCountry', 'TotalPaid', 'StartDate', 'EndDate', 'OrderDate',\n",
    "       'NumberOfPeople']\n",
    "\n",
    "    df = df.loc[:,tgt_cols]\n",
    "\n",
    "    # next rename the data in the data frame\n",
    "    col_names = ['historical_reservation_id', 'order_number', 'agency', 'orgid',\n",
    "           'code_hierarchy', 'region_code', 'region_description',\n",
    "           'parent_location_id', 'parent_location', 'legacy_facility_id',\n",
    "           'park', 'site_type', 'use_type', 'product_id', 'entity_type',\n",
    "           'entity_id', 'facility_id', 'facility_zip', 'facility_state',\n",
    "           'facility_longitude', 'facility_latitude', 'customer_zip',\n",
    "           'customer_state', 'customer_country', 'total_paid', 'start_date',\n",
    "           'end_date', 'order_date', 'number_of_people']\n",
    "\n",
    "    #rename the columns\n",
    "    df.columns = col_names\n",
    "\n",
    "    #Lets only select overnight stays at campsites\n",
    "    df = df.loc[df.use_type == \"Overnight\",:]\n",
    "    df = df.loc[df['entity_type'] == 'Site', :]\n",
    "    \n",
    "    # We will need to coerce the datas into datetime as some of the data isnt clean\n",
    "    for x in [\"start_date\", \"end_date\", \"order_date\"]:\n",
    "        df[x] = pd.to_datetime(df[x],errors=\"coerce\", format=\"%Y-%m-%d\")\n",
    "    \n",
    "    # for some reasons some of these reservations dont have facility ids, we will replace with -1 as a flag\n",
    "    df.facility_id = df.facility_id.fillna(-1).astype(int)\n",
    "    df.entity_id = df.entity_id.fillna(-1).astype(int)    \n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/Reservations/2018.csv\n"
     ]
    }
   ],
   "source": [
    "df = read_data(files[2])\n",
    "df = trim_select_data(df)\n",
    "df.shape\n",
    "\n",
    "# for some reasons some transactions are here multiple times. Lets remove the duplicates\n",
    "df.drop_duplicates(subset=['order_number'], keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_national_park_names = pd.read_csv('../Data/OtherSource/manually_identified_recids_nationalparks.csv')\n",
    "rec_ids_national_parks = df_national_park_names['RecAreaID'].dropna().astype(int).unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df.region_code.isin(rec_ids_national_parks))\n",
    "\n",
    "df.region_code.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Some helpful tutorials on SQLAlchemy and loading data</h3>\n",
    "<a href=\"https://www.freecodecamp.org/news/sqlalchemy-makes-etl-magically-easy-ab2bd0df928/\">Fee Code Camp</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets use the sqlalchemy module, create the table, then load up our data\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, MetaData, Table\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import Column, Integer, String, Numeric, Boolean, DateTime, BigInteger\n",
    "from sqlalchemy.orm import sessionmaker\n",
    " \n",
    "\n",
    "# local postgresql://postgres:79zDvTF9zHfTNJoVQ@localhost/ridb_local\n",
    "engine = create_engine(\"postgresql://postgres:79zDvTF9zHfTNJoVQ@localhost/ridb_local\", echo = False) #Update with credientials\n",
    "Base = declarative_base()\n",
    "\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "\n",
    "meta = MetaData()\n",
    "\n",
    "reservations = Table(\n",
    "    \"reservations\", meta,\n",
    "    Column('order_number', String, primary_key=True),\n",
    "    Column('historical_reservation_id',Numeric),\n",
    "    Column('agency',String),\n",
    "    Column('orgid',Numeric),\n",
    "    Column('code_hierarchy',String),\n",
    "    Column('region_code',String),\n",
    "    Column('region_description',String),\n",
    "    Column('parent_location_id',Numeric),\n",
    "    Column('parent_location',String),\n",
    "    Column('legacy_facility_id',Numeric),\n",
    "    Column('park',String),\n",
    "    Column('site_type',String),\n",
    "    Column('use_type',String),\n",
    "    Column('product_id',Numeric),\n",
    "    Column('entity_type',String),\n",
    "    Column('entity_id',Numeric),    \n",
    "    Column('facility_id',Numeric),\n",
    "    Column('facility_zip',String),\n",
    "    Column('facility_state',String),\n",
    "    Column('facility_longitude',Numeric),\n",
    "    Column('facility_latitude',Numeric),\n",
    "    Column('customer_zip',String),\n",
    "    Column('customer_state',String),\n",
    "    Column('customer_country',String),\n",
    "    Column('total_paid',Numeric),\n",
    "    Column('start_date',DateTime),\n",
    "    Column('end_date',DateTime),\n",
    "    Column('order_date',DateTime),\n",
    "    Column('number_of_people',Numeric)\n",
    ")\n",
    "\n",
    "meta.create_all(engine)\n",
    "\n",
    "session.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After creating the table we want with sqlalchemy orm I realiezed it is a bit tough to test and execute insert statements. \n",
    "# for now im falling back on something I already understand well, psycopg.\n",
    "\n",
    "import psycopg2\n",
    "\n",
    "connection = psycopg2.connect(\n",
    "    host=\"localhost\", \n",
    "    dbname=\"ridb_local\", \n",
    "    user=\"postgres\", \n",
    "    password=\"79zDvTF9zHfTNJoVQ\")\n",
    "\n",
    "connection.autocommit = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_execute_batch(connection, records) -> None:\n",
    "    with connection.cursor() as cursor:\n",
    "        psycopg2.extras.execute_batch(cursor, \"\"\"\n",
    "                INSERT INTO reservations VALUES (\n",
    "                    %(order_number)s,\n",
    "                    %(historical_reservation_id)s,\n",
    "                    %(agency)s,\n",
    "                    %(orgid)s,\n",
    "                    %(code_hierarchy)s,\n",
    "                    %(region_code)s,\n",
    "                    %(region_description)s,\n",
    "                    %(parent_location_id)s,\n",
    "                    %(parent_location)s,\n",
    "                    %(legacy_facility_id)s,\n",
    "                    %(park)s,\n",
    "                    %(site_type)s,\n",
    "                    %(use_type)s,\n",
    "                    %(product_id)s,\n",
    "                    %(entity_type)s,\n",
    "                    %(entity_id)s,\n",
    "                    %(facility_id)s,\n",
    "                    %(facility_zip)s,\n",
    "                    %(facility_state)s,\n",
    "                    %(facility_longitude)s,\n",
    "                    %(facility_latitude)s,\n",
    "                    %(customer_zip)s,\n",
    "                    %(customer_state)s,\n",
    "                    %(customer_country)s,\n",
    "                    %(total_paid)s,\n",
    "                    %(start_date)s,\n",
    "                    %(end_date)s,\n",
    "                    %(order_date)s,\n",
    "                    %(number_of_people)s\n",
    "                );\n",
    "            \"\"\", records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_execute_batch(connection=connection, records=records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0:1000,:].to_csv(\"../Data/Reservations/tempres.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SMOKEY BEAR RD -FS']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions = df.region_description.unique().tolist()\n",
    "[x for x in regions if 'smokey' in x.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['historical_reservation_id', 'order_number', 'agency', 'orgid',\n",
       "       'code_hierarchy', 'region_code', 'region_description',\n",
       "       'parent_location_id', 'parent_location', 'legacy_facility_id',\n",
       "       'park', 'site_type', 'use_type', 'product_id', 'entity_type',\n",
       "       'entity_id', 'facility_id', 'facility_zip', 'facility_state',\n",
       "       'facility_longitude', 'facility_latitude', 'customer_zip',\n",
       "       'customer_state', 'customer_country', 'total_paid', 'start_date',\n",
       "       'end_date', 'order_date', 'number_of_people'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50921"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df.parent_location.str.lower().str.contains('island').fillna(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "nps = df[df['region_description'].str.contains('National Park')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Shenandoah National Park', 'Yosemite National Park',\n",
       "       'Sequoia & Kings Canyon National Parks',\n",
       "       'Joshua Tree National Park', 'Great Smoky Mountains National Park',\n",
       "       'Grand Canyon National Park', 'Channel Islands National Park',\n",
       "       'Rocky Mountain National Park', 'Lassen Volcanic National Park',\n",
       "       'Theodore Roosevelt National Park', 'Canyonlands National Park',\n",
       "       'Headquarters - Arches National Park',\n",
       "       'North Cascades National Park',\n",
       "       'Sequoia and Kings Canyon National Park',\n",
       "       'Lake Clark National Park and Preserve',\n",
       "       'Black Canyon National Park',\n",
       "       'Headquarters - Mammoth Cave National Park',\n",
       "       'Great Sand Dunes National Park', 'Zion National Park',\n",
       "       'Big Bend National Park', 'Olympic National Park',\n",
       "       'Catoctin National Park', 'Acadia National Park',\n",
       "       'Pinnacles National Park', 'Death Valley National Park',\n",
       "       'Mount Rainier National Park', 'Glacier National Park',\n",
       "       'Bryce Canyon National Park', 'Great Basin National Park 02',\n",
       "       'Kenai Fjords National Park', 'Everglades National Park'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nps['region_description'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets read in the list I stored in the manual ridb meta data notebook\n",
    "%store -r facilites_scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "498"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(facilites_scope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['historical_reservation_id', 'order_number', 'agency', 'orgid',\n",
       "       'code_hierarchy', 'region_code', 'region_description',\n",
       "       'parent_location_id', 'parent_location', 'legacy_facility_id',\n",
       "       'park', 'site_type', 'use_type', 'product_id', 'entity_type',\n",
       "       'entity_id', 'facility_id', 'facility_zip', 'facility_state',\n",
       "       'facility_longitude', 'facility_latitude', 'customer_zip',\n",
       "       'customer_state', 'customer_country', 'total_paid', 'start_date',\n",
       "       'end_date', 'order_date', 'number_of_people'], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alirght lets see how many reservations we have \n",
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "518590"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df.facility_id.isin(facilites_scope))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nps = df[df.facility_id.isin(facilites_scope)]\n",
    "\n",
    "len(df_nps['region_description'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
